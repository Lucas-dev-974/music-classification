{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 23:50:52.211370: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-08 23:50:52.212960: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-08 23:50:52.244838: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-08 23:50:52.245343: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 23:50:52.926477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Pour le dataframe\n",
    "import numpy as np # Pour la normalisation et calculs de moyenne\n",
    "import matplotlib.pyplot as plt # Pour la visualisation\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import librosa # Pour l'extraction des features et la lecture des fichiers wav\n",
    "import librosa.display # Pour récupérer les spectrogrammes des audio\n",
    "import librosa.feature\n",
    "\n",
    "import os # C'est ce qui va nous permettre d'itérer sur les fichiers de l'environnement de travail\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve, RandomizedSearchCV # Split de dataset et optimisation des hyperparamètres\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score, zero_one_loss, classification_report # Métriques pour la mesure de performances\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "\n",
    "import tensorflow as tf # Pour le reseau de neurones simple et pour le CNN\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "\n",
    "column_names = ['zcr', 'spectral_c', 'rolloff', 'mfcc1', 'mfcc2', 'mfcc3',\n",
    "                'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9',\n",
    "                'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15',\n",
    "                'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'label']\n",
    "\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# Définissons la liste avec les genres :\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', \n",
    "          'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "# Création d'un dictionnaire avec les genres vide :\n",
    "audio_files = {}\n",
    "\n",
    "\n",
    "for g in genres:\n",
    "  audio_files[g] = []\n",
    "\n",
    "# Remplissage du dictionnaire en important les fichiers audio avec Librosa :\n",
    "for g in genres:\n",
    "  for audio in os.listdir(f'./dataset/genres_original/{g}'):\n",
    "    audio_files[g].append(librosa.load(f'./dataset/genres_original/{g}/{audio}')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_pipeline(audio):\n",
    "  features = []\n",
    "\n",
    "  # Calcul du ZCR\n",
    "\n",
    "  zcr = librosa.zero_crossings(audio)\n",
    "  features.append(sum(zcr))\n",
    "\n",
    "  # Calcul de la moyenne du Spectral centroid\n",
    "\n",
    "  spectral_centroids = librosa.feature.spectral_centroid(y=audio)[0]\n",
    "  features.append(np.mean(spectral_centroids))\n",
    "  \n",
    "  # Calcul du spectral rolloff point\n",
    "\n",
    "  rolloff = librosa.feature.spectral_rolloff(y=audio)\n",
    "  features.append(np.mean(rolloff))\n",
    "\n",
    "  # Calcul des moyennes des MFCC\n",
    "\n",
    "  mfcc = librosa.feature.mfcc(y=audio)\n",
    "\n",
    "  for x in mfcc:\n",
    "    features.append(np.mean(x))\n",
    "\n",
    "\n",
    "  return features\n",
    "\n",
    "# Définissons les noms des colonnes\n",
    "\n",
    "column_names = ['zcr', 'spectral_c', 'rolloff', 'mfcc1', 'mfcc2', 'mfcc3',\n",
    "                'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9',\n",
    "                'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15',\n",
    "                'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'label']\n",
    "\n",
    "# Création d'un dataframe vide\n",
    "\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# On itère sur les audios pour remplir le dataframe\n",
    "\n",
    "i = 0\n",
    "for g in genres:\n",
    "  for music in audio_files[g]:\n",
    "    df.loc[i] = audio_pipeline(music)+[g]\n",
    "    i+=1\n",
    "df.to_csv('music3.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (711, 23)\n",
      "Training Labels Shape: (711, 10)\n",
      "Testing Features Shape: (238, 23)\n",
      "Testing Labels Shape: (238, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('music.csv')\n",
    "# features = pd.read_csv('music.xls')\n",
    "features = df\n",
    "# One-hot encode\n",
    "labels = pd.get_dummies(features['label'])\n",
    "# enleve les labels des features\n",
    "features = features.drop('label', axis = 1)\n",
    "# sauvegarde la liste des features\n",
    "feature_list = list(features.columns)\n",
    "# conversion en numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.25, random_state = 0)\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "# scaling\n",
    "sc = StandardScaler()\n",
    "train_features = sc.fit_transform(train_features)\n",
    "test_features = sc.transform(test_features)\n",
    "\n",
    "joblib.dump(sc, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 161)               3864      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1620      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 5484 (21.42 KB)\n",
      "Trainable params: 5484 (21.42 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "8/8 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [949, 238]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_features)\n\u001b[1;32m     15\u001b[0m pred_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(predictions, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[0;32m---> 16\u001b[0m confusion_mtx \u001b[39m=\u001b[39m confusion_matrix(np\u001b[39m.\u001b[39;49margmax(labels, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), pred_classes)\n\u001b[1;32m     18\u001b[0m \u001b[39m# evaluation du modèle\u001b[39;00m\n\u001b[1;32m     19\u001b[0m _, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_features, test_labels, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Work/Simplon/music-classification/api/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/Work/Simplon/music-classification/api/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/Work/Simplon/music-classification/api/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Work/Simplon/music-classification/api/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [949, 238]"
     ]
    }
   ],
   "source": [
    "# création du modèle\n",
    "model = Sequential()\n",
    "model.add(Dense(161, input_dim=23, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# fit le modèle\n",
    "history = model.fit(train_features, train_labels, epochs=200, batch_size=20, verbose=0)\n",
    "\n",
    "# prédiction\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "pred_classes = np.argmax(predictions, axis=1) \n",
    "confusion_mtx = confusion_matrix(np.argmax(labels, axis=1), pred_classes)\n",
    "\n",
    "# evaluation du modèle\n",
    "_, accuracy = model.evaluate(test_features, test_labels, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "model.save(\"neuralNetwork.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1 disco 95.74%\n",
      "2 hiphop 3.83%\n",
      "3 rock 0.37%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and preprocess the audio file\n",
    "def preprocess_audio(file_path):\n",
    "    audio, _ = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Apply the same feature extraction and scaling as you did during training\n",
    "    features = audio_pipeline(audio)\n",
    "    scaled_features = sc.transform([features]) \n",
    "    \n",
    "    return scaled_features\n",
    "\n",
    "# Make predictions on the preprocessed audio\n",
    "def predict_top_genres(file_path, top_n=3):\n",
    "    scaled_features = preprocess_audio(file_path)\n",
    "    predicted_probabilities = model.predict(scaled_features)\n",
    "    top_n_indices = np.argsort(predicted_probabilities[0])[::-1][:top_n]\n",
    "    top_n_genres = [genres[idx] for idx in top_n_indices]\n",
    "    prediction_percentages = [predicted_probabilities[0][idx] * 100 for idx in top_n_indices]\n",
    "    return top_n_genres, prediction_percentages\n",
    "\n",
    "# Provide the path to the audio file you want to classify\n",
    "audio_file_path = './dataset/to_check/sound/hiphop/hiphop.00000.wav'\n",
    "top_genres, prediction_percentages = predict_top_genres(audio_file_path)\n",
    "\n",
    "for i, genre in enumerate(top_genres):\n",
    "    print( i+1, genre,'{:.2f}%'.format(prediction_percentages[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
